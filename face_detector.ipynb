{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from eye import Eye\n",
    "from calibration import Calibration\n",
    "import dlib\n",
    "import os\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calibration = Calibration()\n",
    "\n",
    "#_face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "_predictor = dlib.shape_predictor(\"trained_models/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pupils_located(eye_left,eye_right):\n",
    "    try:\n",
    "        int(eye_left.pupil.x)\n",
    "        int(eye_left.pupil.y)\n",
    "        int(eye_right.pupil.x)\n",
    "        int(eye_right.pupil.y)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def pupil_left_coords(eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        x = eye_left.origin[0] + eye_left.pupil.x\n",
    "        y = eye_left.origin[1] + eye_left.pupil.y\n",
    "        return (x, y)\n",
    "\n",
    "def pupil_right_coords(eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        x = eye_right.origin[0] + eye_right.pupil.x\n",
    "        y = eye_right.origin[1] + eye_right.pupil.y\n",
    "        return (x, y)\n",
    "\n",
    "def annotated_frame(frame_g,eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        color = (0, 255, 0)\n",
    "        x_left, y_left = pupil_left_coords(eye_left,eye_right)\n",
    "        x_right, y_right = pupil_right_coords(eye_left,eye_right)\n",
    "        cv2.line(frame, (x_left - 5, y_left), (x_left + 5, y_left), color)\n",
    "        cv2.line(frame, (x_left, y_left - 5), (x_left, y_left + 5), color)\n",
    "        cv2.line(frame, (x_right - 5, y_right), (x_right + 5, y_right), color)\n",
    "        cv2.line(frame, (x_right, y_right - 5), (x_right, y_right + 5), color)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "def horizontal_ratio(eye_left,eye_right):\n",
    "      \n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        pupil_left = eye_left.pupil.x / (eye_left.center[0] * 2 - 10)\n",
    "        pupil_right = eye_right.pupil.x / (eye_right.center[0] * 2 - 10)\n",
    "        return (pupil_left + pupil_right) / 2\n",
    "\n",
    "def vertical_ratio(eye_left,eye_right):\n",
    "\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        pupil_left = eye_left.pupil.y / (eye_left.center[1] * 2 - 10)\n",
    "        pupil_right = eye_right.pupil.y / (eye_right.center[1] * 2 - 10)\n",
    "        return (pupil_left + pupil_right) / 2\n",
    "\n",
    "def is_right(eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        return horizontal_ratio(eye_left,eye_right) <= 0.35\n",
    "\n",
    "def is_left(eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        return horizontal_ratio(eye_left,eye_right) >= 0.65\n",
    "\n",
    "def is_center(eye_left,eye_right):\n",
    "    if pupils_located(eye_left,eye_right):\n",
    "        return is_right(eye_left,eye_right) is not True and is_left(eye_left,eye_right) is not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    key_pressed = cv2.waitKey(1)&0xFF\n",
    "    if ret==False:\n",
    "        print(\"Something went wrong\")\n",
    "        continue\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "    frame_g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = detector.detect_faces(frame)\n",
    "    for i in range(len(faces)) :\n",
    "        \n",
    "        #eye gaze --------------------------------------------------------\n",
    "        \n",
    "        eye_left = None\n",
    "        eye_right = None\n",
    "        bounding_box = faces[i]['box']\n",
    "        x1, y1, width, height = bounding_box\n",
    "#         face = [(x1,y1),(x1+width,y1+height)]\n",
    "        face = dlib.rectangle(x1,y1,x1+width,y1+height)\n",
    "        try:\n",
    "            landmarks = _predictor(frame, face)\n",
    "            \n",
    "\n",
    "        except IndexError:\n",
    "            eye_left = None\n",
    "            eye_right = None\n",
    "            \n",
    "        frame = annotated_frame(frame_g,eye_left,eye_right)\n",
    "        \n",
    "        text=\"\"\n",
    "        if is_right(eye_left,eye_right):\n",
    "            text = \"Looking right\"\n",
    "        elif is_left(eye_left,eye_right):\n",
    "            text = \"Looking left\"\n",
    "        elif is_center(eye_left,eye_right):\n",
    "            text = \"Looking center\"\n",
    "        \n",
    "        \n",
    "        cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2)\n",
    "\n",
    "        left_pupil = pupil_left_coords(eye_left,eye_right)\n",
    "        right_pupil = pupil_right_coords(eye_left,eye_right)\n",
    "        cv2.putText(frame, \"Left pupil:  \" + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        cv2.putText(frame, \"Right pupil: \" + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(frame,(bounding_box[0], bounding_box[1]),(bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),(0,155,255),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"faces\",frame)\n",
    "    \n",
    "\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    key_pressed = cv2.waitKey(1)&0xFF\n",
    "    if ret==False:\n",
    "        print(\"Something went wrong\")\n",
    "        continue\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "    frame_g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = detector.detect_faces(frame)\n",
    "    for i in range(len(faces)) :\n",
    "        \n",
    "        #eye gaze --------------------------------------------------------\n",
    "        \n",
    "        eye_left = None\n",
    "        eye_right = None\n",
    "        bounding_box = faces[i]['box']\n",
    "        x1, y1, width, height = bounding_box\n",
    "#         face = [(x1,y1),(x1+width,y1+height)]\n",
    "        face = dlib.rectangle(x1,y1,x1+width,y1+height)\n",
    "        try:\n",
    "            landmarks = _predictor(frame, face)\n",
    "            eye_left = Eye(frame_g, landmarks, 0, calibration)\n",
    "            eye_right = Eye(frame_g, landmarks, 1, calibration)\n",
    "\n",
    "        except IndexError:\n",
    "            eye_left = None\n",
    "            eye_right = None\n",
    "            \n",
    "        frame = annotated_frame(frame_g,eye_left,eye_right)\n",
    "        \n",
    "        text=\"\"\n",
    "        if is_right(eye_left,eye_right):\n",
    "            text = \"Looking right\"\n",
    "        elif is_left(eye_left,eye_right):\n",
    "            text = \"Looking left\"\n",
    "        elif is_center(eye_left,eye_right):\n",
    "            text = \"Looking center\"\n",
    "        \n",
    "        \n",
    "        cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2)\n",
    "\n",
    "        left_pupil = pupil_left_coords(eye_left,eye_right)\n",
    "        right_pupil = pupil_right_coords(eye_left,eye_right)\n",
    "        cv2.putText(frame, \"Left pupil:  \" + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        cv2.putText(frame, \"Right pupil: \" + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(frame,(bounding_box[0], bounding_box[1]),(bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),(0,155,255),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"faces\",frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_GPU",
   "language": "python",
   "name": "ml_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
