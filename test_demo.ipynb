{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from calibration import Calibration\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0507 13:49:49.596323 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0507 13:49:49.613246 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0507 13:49:49.643166 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0507 13:49:49.645161 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0507 13:49:49.646158 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0507 13:49:49.653140 72692 deprecation.py:506] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0507 13:49:49.847620 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0507 13:49:51.525099 72692 deprecation_wrapper.py:119] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0507 13:49:51.533083 72692 deprecation.py:323] From C:\\Users\\asus\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./trained_models/model.h5')\n",
    "model_eye = load_model('./trained_models/eye_model.h5')\n",
    "calibration = Calibration()\n",
    "_predictor = dlib.shape_predictor(\"trained_models/shape_predictor_68_face_landmarks.dat\")\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixele_test(img_array, required_size=(60, 60)):\n",
    "    image = Image.fromarray(img_array)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)/255\n",
    "    return face_array\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((30,30))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    img = img.reshape(30, 30, 1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_eyes(faces,frame_g):\n",
    "    bounding_box = faces[i]['box']\n",
    "    x1, y1, width, height = bounding_box\n",
    "#         face = [(x1,y1),(x1+width,y1+height)]\n",
    "    face = dlib.rectangle(x1,y1,x1+width,y1+height)\n",
    "    landmarks = _predictor(frame, face)\n",
    "    left_eye = []\n",
    "    right_eye = []\n",
    "    left_eye.append([landmarks.part(36).x,landmarks.part(36).y])\n",
    "    left_eye.append([landmarks.part(37).x,landmarks.part(37).y])\n",
    "    left_eye.append([landmarks.part(38).x,landmarks.part(38).y])\n",
    "    left_eye.append([landmarks.part(39).x,landmarks.part(39).y])\n",
    "    left_eye.append([landmarks.part(40).x,landmarks.part(40).y])\n",
    "    left_eye.append([landmarks.part(41).x,landmarks.part(41).y])\n",
    "\n",
    "    right_eye.append([landmarks.part(42).x,landmarks.part(42).y])\n",
    "    right_eye.append([landmarks.part(43).x,landmarks.part(43).y])\n",
    "    right_eye.append([landmarks.part(44).x,landmarks.part(44).y])\n",
    "    right_eye.append([landmarks.part(45).x,landmarks.part(45).y])\n",
    "    right_eye.append([landmarks.part(46).x,landmarks.part(46).y])\n",
    "    right_eye.append([landmarks.part(47).x,landmarks.part(47).y])\n",
    "\n",
    "    left_eye = np.array(left_eye)\n",
    "    right_eye = np.array(right_eye)\n",
    "\n",
    "    rect_left = cv2.boundingRect(left_eye)\n",
    "    x,y,w,h = rect_left\n",
    "    txt_left = (x,y)\n",
    "    croped_left = frame_g[y:y+h, x:x+w].copy()\n",
    "\n",
    "    left_eye = left_eye - left_eye.min(axis=0)\n",
    "    cv2.polylines(croped_left, np.array([left_eye], int), True, (0,0,0), 2)\n",
    "    mask_left = np.zeros(croped_left.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask_left, [left_eye], -1, (255, 0, 0), -1, cv2.LINE_AA)\n",
    "    dst_left = cv2.bitwise_and(croped_left, croped_left, mask=mask_left)\n",
    "#         cv2.imshow(\"left\",dst_left)\n",
    "\n",
    "    rect_right = cv2.boundingRect(right_eye)\n",
    "    x,y,w,h = rect_right\n",
    "    txt_right = (x,y)\n",
    "    croped_right = frame_g[y:y+h, x:x+w].copy()\n",
    "    right_eye = right_eye - right_eye.min(axis=0)\n",
    "    cv2.polylines(croped_right, np.array([right_eye], int), True, (0,0,0), 2)\n",
    "    mask_right = np.zeros(croped_right.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask_right, [right_eye], -1, (255, 0, 0), -1, cv2.LINE_AA)\n",
    "    dst_right = cv2.bitwise_and(croped_right, croped_right, mask=mask_right)\n",
    "#         cv2.imshow(\"right\",dst_right)\n",
    "    left_eye_img = preprocess_img(dst_left)\n",
    "    right_eye_img = preprocess_img(dst_right)\n",
    "\n",
    "    left_pred = model_eye.predict(left_eye_img)\n",
    "    right_pred = model_eye.predict(right_eye_img)\n",
    "    pred_eye = []\n",
    "    pred_eye.append(left_pred)\n",
    "    pred_eye.append(right_pred)\n",
    "    return pred_eye\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cam = cv2.VideoCapture(0)\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX \n",
    " \n",
    "# fontScale = 1\n",
    "# color = (255, 0, 0) \n",
    "# thickness = 2\n",
    "\n",
    "# while(True):\n",
    "#     ret,frame = cam.read()\n",
    "#     key_pressed = cv2.waitKey(1)&0xFF\n",
    "#     if ret==False:\n",
    "#         print(\"Something went wrong\")\n",
    "#         continue\n",
    "#     if key_pressed == ord('q'):\n",
    "#         break\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     frame_g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# #     frame = cv2.flip(frame, 1)\n",
    "#     faces = detector.detect_faces(frame)\n",
    "#     for i in range(len(faces)):\n",
    "#         bb = faces[i]['box']\n",
    "#         x, y, w, h = bb\n",
    "#         f_img = frame[y:y+h,x:x+w]\n",
    "#         face = get_pixele_test(f_img)\n",
    "#         face = np.expand_dims(face, axis=0)\n",
    "#         pred = model.predict(face)\n",
    "        \n",
    "#         if pred>0.5:\n",
    "#             frame = cv2.rectangle(frame, (int(x),int(y)), (int(x+w),int(y+h)), (0, 255, 0), thickness)\n",
    "#             pred_eyes = prediction_eyes(faces,frame_g)\n",
    "# #             print(pred_eyes)\n",
    "#             if pred_eyes[0]>0.5 or pred_eyes[1]>0.5:\n",
    "#                 cv2.putText(frame,\"cheating_eyes\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 2, cv2.LINE_AA)\n",
    "#             else:\n",
    "#                 cv2.putText(frame,\"ok\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "#         else:\n",
    "#             frame = cv2.rectangle(frame, (int(x),int(y)), (int(x+w),int(y+h)), (255, 0, 0), thickness)\n",
    "            \n",
    "#             pred_eyes = prediction_eyes(faces,frame_g)\n",
    "# #             print(pred_eyes)\n",
    "#             if pred_eyes[0]>=0.9 and pred_eyes[1]>=0.9:\n",
    "#                 cv2.putText(frame,\"cheating_eyes\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 1, cv2.LINE_AA)\n",
    "#             else:\n",
    "#                 cv2.putText(frame,\"Ok\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     cv2.imshow('yo', frame)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7a0975dfe193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mframe_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#     frame = cv2.flip(frame, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;31m#     print(len(faces))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;31m# We pipe here each of the stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mtotal_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36m__stage2\u001b[1;34m(self, img, total_boxes, stage_status)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0mtempimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempimg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mout0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML_GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cams = []\n",
    "path = \"./final_dataset/test\"\n",
    "for root,dirs,files in os.walk(path):\n",
    "    for file in files:\n",
    "        cams.append(cv2.VideoCapture(path+'/'+file))\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    " \n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2\n",
    "\n",
    "while(True):\n",
    "    for n,cam in enumerate(cams[:2]):   \n",
    "        ret,frame = cam.read()\n",
    "        frame = Image.fromarray(frame)\n",
    "        frame = frame.resize((640,480))\n",
    "        frame = np.array(frame)\n",
    "        \n",
    "        key_pressed = cv2.waitKey(1)&0xFF\n",
    "    #     frame = final_frame\n",
    "        if ret==False:\n",
    "            print(\"Something went wrong\")\n",
    "            continue\n",
    "        if key_pressed == ord('q'):\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #     frame = cv2.flip(frame, 1)\n",
    "        faces = detector.detect_faces(frame)\n",
    "    #     print(len(faces))\n",
    "        for i in range(len(faces)):\n",
    "            bb = faces[i]['box']\n",
    "            x, y, w, h = bb\n",
    "            f_img = frame[y:y+h,x:x+w]\n",
    "            face = get_pixele_test(f_img)\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            pred = model.predict(face)\n",
    "            if pred>0.5:\n",
    "                frame = cv2.rectangle(frame, (int(x),int(y)), (int(x+w),int(y+h)), (0, 255, 0), thickness)\n",
    "            else:\n",
    "                frame = cv2.rectangle(frame, (int(x),int(y)), (int(x+w),int(y+h)), (255, 0, 0), thickness)\n",
    "                pred_eyes = prediction_eyes(faces,frame_g)\n",
    "    #             print(pred_eyes)\n",
    "                if pred_eyes[0]>=0.5 and pred_eyes[1]>=0.5:\n",
    "                    cv2.putText(frame,\"cheating_eyes\",(int(x),int(y)),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 1, cv2.LINE_AA)\n",
    "                else:\n",
    "                    cv2.putText(frame,\"Ok\",(int(x),int(y)),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        if n==0:\n",
    "            final_frame = frame\n",
    "        else:\n",
    "            final_frame = np.hstack((final_frame,frame))\n",
    "    cv2.imshow('yo', final_frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_GPU",
   "language": "python",
   "name": "ml_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
